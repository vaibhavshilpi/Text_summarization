{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "908ec211-3aae-4cc5-aaad-9a2729b7c7b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49629277-4dbc-495f-a26d-c3ee9fa600f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "836d1c92-f976-4607-9b93-1927f70fc471",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_text(text, num_sentences=3):\n",
    "    # Tokenize into sentences\n",
    "    sentences = sent_tokenize(text)\n",
    "\n",
    "    # Tokenize into words and calculate word frequencies\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    word_frequencies = {}\n",
    "    for word in word_tokenize(text.lower()):\n",
    "        if word not in stop_words and word not in string.punctuation:\n",
    "            if word not in word_frequencies:\n",
    "                word_frequencies[word] = 1\n",
    "            else:\n",
    "                word_frequencies[word] += 1\n",
    "\n",
    "    # Score each sentence\n",
    "    sentence_scores = {}\n",
    "    for sentence in sentences:\n",
    "        for word in word_tokenize(sentence.lower()):\n",
    "            if word in word_frequencies:\n",
    "                if len(sentence.split()) < 30:  # Ignore very long sentences\n",
    "                    if sentence not in sentence_scores:\n",
    "                        sentence_scores[sentence] = word_frequencies[word]\n",
    "                    else:\n",
    "                        sentence_scores[sentence] += word_frequencies[word]\n",
    "\n",
    "    # Select top N sentences\n",
    "    summary_sentences = sorted(sentence_scores, key=sentence_scores.get, reverse=True)[:num_sentences]\n",
    "    \n",
    "    # Combine summary sentences\n",
    "    summary = ' '.join(summary_sentences)\n",
    "    return summary\n",
    "\n",
    "# Example usage\n",
    "text = \"\"\"\n",
    "Natural language processing (NLP) is a field of artificial intelligence that focuses on the interaction between computers and humans through natural language.\n",
    "The ultimate goal of NLP is to enable computers to understand, interpret, and generate human languages.\n",
    "It is used in a variety of applications including speech recognition, machine translation, and sentiment analysis.\n",
    "NLTK is one of the most commonly used Python libraries for NLP.\n",
    "It provides easy-to-use interfaces to over 50 corpora and lexical resources.\n",
    "\"\"\"\n",
    "\n",
    "summary = summarize_text(text, num_sentences=2)\n",
    "print(\"Summary:\\n\", summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2555babe-4e9f-433f-b1fd-d22da98b7bcc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
